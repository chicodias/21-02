---
title: "SME0809 - Inferência Bayesiana - Prova 2"
subtitle: High-Dimensional Multivariate Bayesian Variable and Covariance Selection in Linear Regression
author: "Grupo 13 - Francisco Miranda - 4402962 - Heitor Carvalho - 11833351"
date: "Dezembro 2021"
institution: "Universidade de São Paulo"
output: 
  xaringan::moon_reader:
    css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    seal: true # show a title slide with YAML information
    includes:
      in_header: "assets/mathjax-equation-numbers.html"
    nature:
      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```

```{r bibs, echo = FALSE, cache=TRUE}

library(RefManageR)
BibOptions(
bib.style = "authoryear", 
cite.style = "authoryear", 
style = "markdown",
hyperlink = FALSE, 
dashed = FALSE)
myBib <- ReadBib("packages.bib")
```


## Introdução 

Com o desenvolvimento de técnicas de alto processamento na biologia molecular, a caracterização molecular em alta escala tornou-se um lugar comum, com o advento de técnicas como:

 - Genome-wide measurement of gene expression
 - Single nucleotide polymorphisms
 - CpG methylation status
 - Pharmacological profiling for large-scale cancer drug screen.
 
A análise de associações conjuntas entre múltiplos fenótipos correlacionados e atributos moleculares de alta dimensionalidade é desafiadora.

---

## Introdução 

Quando múltiplos fenótipos e informação genômica de alta dimensionalidade são analisados conjuntamente, a abordagem bayesiana permite especificar de maneira flexível as relações complexas entre os conjunto de dados altamente estruturados.

O pacote `BayesSUR` combina diversos modelos que foram propostos para a regressão multidimentional com resposta múltipla e introduz um novo modelo, que permite diferentes *prioris* na seleção de variáveis dos modelos de regressão e para diferentes pressupostos a respeito da estrutura de dependência entre as respostas.

---

## Metodologia

O modelo de regressão é escrito como:
 
\begin{align}
\boldsymbol{Y} = \boldsymbol{XB} + \boldsymbol{U} \label{eq:1}
\end{align}
$$\text{vec}{(\boldsymbol{U})} \sim \mathcal{N}(\boldsymbol{0}, C \otimes \mathbb{I}_n) $$

onde:

 - $\boldsymbol{Y}$ é uma matriz $s \times s$ das variáveis resposta com matriz de covariância C;
 - $\boldsymbol{X}$ é uma matriz $n \times p$ de preditores para todas as respostas;
 - $\boldsymbol{U}$ é a matriz dos resíduos;
 - $\text{vec}(\cdot)$ denota a vetorização da matriz;
 - $\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})$ denota uma distribuição normal multivariada com vetor de médias $\boldsymbol{\mu}$ e matriz de covariâncias $\boldsymbol{\Sigma}$;
 - $\boldsymbol{0}$ denota um vetor coluna com todos os elementos nulos,
 - $\otimes$ é o produto de Kronecker e $\mathbb{I}_n$ a matriz identidade de ordem $n$.

---

## Seleção de Variáveis

A seleção de variáveis é realizada através de uma matriz indicadora binária latente $\boldsymbol{\Gamma} = \{\gamma_{jk}\}$.

Uma *priori* "pico e tapa" é utilizada para encontrar um subconjunto de preditores que expliquem a variabilidade de $\boldsymbol{Y}$: condicional em $\gamma_{jk} = 0\ \ (j = 1, ..., p, \text{e}\ k=1, ..., s)$

$\beta_{jk} = 0$ condicionado em $\gamma_{jk} = 1$ segue uma distribuição normal difusa:

\begin{align}
\beta_\gamma \sim \mathcal{N}(\textbf{0}, W^{-1}_\gamma) \label{eq:2}
\end{align}

Onde:

 - $\beta = \text{vec}(\textbf{B})$, $\gamma = \text{vec}( \boldsymbol{\Gamma})$
 - $\beta_\gamma$ consiste somente nos coeficientes selecionados (i.e. $\gamma_{jk} = 1$), assim $W_\gamma$ é a sub matriz de W formada pelos coeficientes selecionados correspondentes.

A matriz de precisão $W$ utilizada aqui é da forma $W = w^{-1} \mathbb{I}_{sp}$, o que significa que todos os coeficientes de regressão são independentes a priori, com uma *hiperpriori* no coeficiente de encolhimento $w$, i.e. $w \sim \mathcal{IG}\text{amma}(a_w, b_w)$.

---

## Modelos Hierárquicos

O pacote `BayesSUR` suporta uma gama de nove possíveis modelos dentre as combinações de $C$, a matriz de covariância (que pode ser esparsa, densa, ou independente), e a matriz indicadora binária latente $\boldsymbol \Gamma$.

|  | ${\gamma_{jk}} \sim Bernoulli$ | $\gamma_{jk} \sim$ hotspot | $\gamma_{jk} \sim$ MRF |
|:---:|:---:|:---:|:---:|
| $C\sim indep$ | HRR-B | HRR-H | HRR-M |
| $C\sim IW$ | dSUR-B | dSUR-H | dSUR-M |
| $C\sim HIW$ | SSUR-B | SSUR-H | SSUR-M |


---

##  Regressão Hierárquica Relacionada (HRR)

A Regressão Hierárquica Relacionada assume que $C$ é uma matriz diagonal, o que se traduz em independência condicional entre múltiplas variáveis resposta.

Uma *priori* gama inversa é especificada para a covariância dos resíduos:

$$\sigma^2_k \sim \mathcal{IG}\text{amma}(a_\sigma, b_\sigma)$$

Quando combinada com as *prioris* em \eqref{eq:2}, é conjulgado com a verossimilhança do modelo \eqref{eq:1}. Podemos então amostrar a estrutura de seleção de variáveis $\boldsymbol{\Gamma}$ marginalmente com respeito a $C$ e $\boldsymbol B$.


---

## HRR com uma *priori* Bernouli independente

Para uma *priori* simples de seleção do modelo de regressão, os indicadores binários latentes seguem uma *priori* de Bernoulli:

\begin{align}
\gamma_{jk}|\omega_{jk} \sim \mathcal Ber(\omega_{jk})\ \ (j = 1, ..., p, \text{e}\ k=1, ..., s)  \label{eq:3}
\end{align}


Assim, temos uma priori hierárquica Beta em $\omega_j$, i.e. $\omega_j \sim \mathcal Beta(a_\omega, b_\omega)$, que quantifica a probabilidade de cada preditor ser associado com qualquer uma das variáveis resposta.


---

## HRR com uma *priori* hotspot

É proposta a decomposição da probabilidade do parâmetro de associação $\omega_{jk}$ em \eqref{eq:3}, onde $o_k$ é responsável pela esparsividade de cada modelo de resposta e $\pi_j$ controla a propensão de cada preditor a ser associado a múltiplas respostas simuntaneamente:

\begin{align}
\gamma_{jk}|\omega_{jk} \sim \mathcal Ber(\omega_{jk})\ \ (j = 1, ..., p, \text{e}\ k=1, ..., s)  \label{eq:4} 
\end{align}
$$\begin{gathered}
\omega_{jk} = o_k \times \pi_j \\
o_k \sim \mathcal Beta (a_0, b_0) \\
\pi_j \sim \mathcal Gamma(a_\pi, b_\pi)
\end{gathered}$$

---

## Regressão não relacionada aparentemente esparsa (SSUR)

A matriz de covariância $C$ é modelada através de um grafo corresponde à matriz esparsa de precisão $C^{-1}$, com *priori* Wishart hiper-Inversa. É impraticável computacionalmente especificar a priori dessa distribuição diretamente em $C^{-1}$.

A distribuição hiper inversa de Wishart i.e $C \sim \mathcal{HIW}_\mathcal G(\nu, \tau \mathbb I_s)$ é fatorada na variância escalar $\sigma^2_{qt}$ e no vetor de correlação associado $\boldsymbol \rho _{qt} = ( \rho _{1,qt},  \rho _{2,qt}, ...  ,\rho _{t-1,qt})^T$, com:


\begin{equation}
\sigma^2_{qt} \sim \mathcal{IG}amma \left(\frac{\nu - s + t + |S_q|}{2}, \frac \tau 2 \right), \  q = 1, ..., Q,\ t = 1,..., |R_q|, \boldsymbol \rho_{qt} | \sigma^2_{qt} \ 
\sim \mathcal N \left(\boldsymbol 0, \frac{\sigma^2_{qt}}{\tau} \mathbb I_{t-1}\right) \label{eq:5}
\end{equation}

onde:
  - $Q$ é o número de componentes primos no grafo decomposto
  - $\mathcal G$, $S_q$ e $R_q$ são os separadores e os componentes residuais de $\mathcal G$, respectivamente.


Como *priori* para $\mathcal G$ é utilizado uma Bernoulli com probabilidade $\eta$ em cada vértice $E_{kk'}$ de $\mathcal G$ como em:

\begin{align}
\mathbb P (E_{kk'} \in \mathcal G) = \eta, \ \ \eta \sim \mathcal Beta (a_\eta, b_\eta) \label{eq:6}
\end{align}

---

## Amostragem MCMC e inferência *a posteriori*


 - Para amostrar da distribuição a *posteriori*, os autores utilizam o algoritmo de busca estocástica evolucionária, que utiliza uma forma particular do Monte Carlo evolucionário (EMC).

 - Múltiplas cadeias de Markov temperadas são processadas paralelamente e movimentos de troca ou mudança são permitidos dentre as cadeias para melhorar a mistura entre modelos potencialmente diferentes da *posteriori*.

 - A cadeia principal provém amostras da distribuição a *posteriori* não-temperada, que é utilizada para toda a inferência.
 
 - Para cada variável resposta, os autores utilizam um amostrador de Gibbs para atualizar o vetor dos coeficientes de regressão $\beta_k(k = 1, ...,s)$, baseado na distribuição a *posteriori* condicional correspondente ao modelo específico, selecionado entre os modelos apresentados anteriormente.

---

## Amostragem MCMC e inferência *a posteriori*

Após $L$ iterações do MCMC, obtêm-se $\boldsymbol B^{(1)}, ..., \boldsymbol B^{(L)}$ e a estimativa da média a *posteriori* é:

$$\hat{\boldsymbol B} = \frac{1}{L-b} \sum^L_{t = b+1} \boldsymbol B^{(t)}$$

onde $b$ é o número de iterações de *burn-in*.

Em cada iteração $t$ do MCMC também é atualizado cada vetor binário latente $\gamma_k(k=1,..., s)$ via Metropolis-Hastings, propondo conjuntamente uma atualização para o correspondente $\beta_k$.

--

Após $L$ iterações, usando as matrizes binárias $\boldsymbol \Gamma^{(1)}, ..., \boldsymbol \Gamma^{(L)}$, as probabilidades de inclusão marginal a *posteriori* são estimadas por:

$$\hat{\boldsymbol \Gamma} = \frac{1}{L-b} \sum^L_{t = b+1} \boldsymbol \Gamma^{(t)}$$

---

## Amostragem MCMC e inferência *a posteriori*

A *priori* Wishart hiper-inversa para a matriz de covariância $C$ é atualizada via _junction tree sampler_ conjuntamente com a proposta correspondente para $\sigma^2_{qt}$ e $\boldsymbol \rho_{qt} | \sigma^2_{qt}$ em  \eqref{eq:5}.

A cada iteração do MCMC é extraída a matriz de adjacência $\mathcal G^{(t)} (t=1,...,L)$, do qual são derivadas as estimativas da média a *posteriori* das probabilidades de inclusão das areastas como:

$$\hat{\mathcal G} = \frac{1}{L-b} \sum^L_{t = b+1} \mathcal G^{(t)}$$

Mesmo que a *priori* o grafo $\mathcal G$ seja decomposto, a média estimada posteriormente $\hat{\mathcal G}$ pode estar fora do espaço de modelos decompostos.

O hiperparâmetro $\tau$ da Wishart hiper-inversa é atualizado através de um passeio aleatório do amostrador Metropolis-Hastings. Já $\eta$ e a variância $w$ na priori pico-e-tapa são amostrados das condicionais posteriores.

---
class: segue-red

# Conjunto de Dados

---

## Conjunto de Dados

Os autores simularam dados de polimorfismo de nucleotídeo único (SNP) dentro de um modelo verdadeiro conhecido para demonstrar a performance de recuperação dos modelos introduzidos anteriormente.

```{r  out.width="50%", out.height="50%", fig.align='center'}

knitr::include_graphics("https://www.onconews.com.br/site/images/artigos/2021/drops_polimorfismos_nucleot%C3%ADdeo_unico.jpg")

```



Para construir variáveis resposta múltiplas $\boldsymbol Y$ (com $s=10$) com uma relação estruturada, os autores fixam uma variável indicadora esparsa $\boldsymbol \Gamma$ e desenham um grafo decomposto para as respostas, para construir padrões de associação dentre os múltiplos regressores e variáveis resposta.

```{r data-load}
# pacote principal
library(BayesSUR)
data("exampleEQTL", package = "BayesSUR")
# attach nos dados para um código mais compacto
attach(exampleEQTL)
```

---

## Conjunto de Dados

```{r prior-graphs,echo=FALSE, message = F}
# bibliotecas para gráficos
library(tidyverse)
library(gridExtra)
library(ggpubr)
library(tictoc)
# funcao que recebe uma matriz e plota um mapa de calor
 plot_heatmap<- function(df){
reshape2::melt(df) %>% ggplot(aes(x=Var1, y=Var2, fill=-value)) + 
    geom_raster() + guides(fill="none") +
    scale_fill_fermenter()
 }
# rotulos da escala
labs <- as_labeller(
          c("1" = "GEX1", "2" =  "GEX2",  "3" =  "GEX3", "4" = "GEX4","5" = "GEX5",
          "6" = "GEX6", "7" = "GEX7", "8" = "GEX8", "9" = "GEX9", "10" = "GEX10"))
# mapa de calor Y versus X
p <- plot_heatmap(gamma) + scale_y_continuous(breaks= 1:10,labels = labs)
# mapa de calor Y versus Y
q <- plot_heatmap(Gy)  + scale_x_continuous(breaks= 1:10,labels = labs)

grid.arrange(p,q, ncol = 2) 
```

O conjunto de dados consiste em 10 colunas, que são as respostas em $\boldsymbol Y$,  150 linhas, que são as regressores em $\boldsymbol X$, e  uma `blockList` que especifica os índices de $\boldsymbol Y$ e $\boldsymbol X$

---

## Análise dos Dados

Os autores utilizam o exemplo para ajustar um modelo SSUR com uma *priori* *hotspot* para as variáveis indicadoras $\boldsymbol \Gamma$ e a *priori* indutora de esparsidão Wishart hiper-inversa utilizando o pacote `BayesSUR`.

No exemplo são 200000 iterações do MCMC, com burn-in de 100000, em três cadeias paralelamente. Para manter a reprodutibilidade, o código foi executado em um único núcleo.

```{r model-fit, echo= TRUE, message=FALSE, eval=FALSE}
library(BayesSUR)
library(tictoc)

set.seed(28173)
tic("Tempo de ajuste do modelo")
# ajuste do modelo
fit <- BayesSUR(data = data, Y = blockList[[1]], X = blockList[[2]],
                outFilePath = "results-hiw-hotspot", nIter = 200000, nChains = 3,
                burnin = 100000, covariancePrior = "HIW",
                gammaPrior = "hotspot",
                output_CPO = TRUE
                )
toc()
```

O ajuste demorou cerca de 90 minutos.

```{r model-read, echo = FALSE}
# ler o modelo ja ajustado
load("results-hiw-hotspot/obj_BayesSUR.RData")
fit <- obj_BayesSUR
class(fit) <- "BayesSUR"
```

---

## Análise dos Dados

Resultados da inferência a posteriori dos estimadores $\hat{\boldsymbol B}, \hat{\boldsymbol \Gamma}, \text{e} \ \hat{\mathcal G}$.


```{r plt-beta, echo  = FALSE}
# plota estimador beta
plotEstimator(fit, estimator = c("gamma","Gy"))
```

---

## Análise dos Dados

```{r plt-gamma, echo  = FALSE, fig.cap = "Coeficientes estimados da matriz indicadora latente $\\hat{ \\boldsymbol \\Gamma}$"}
# plota estimador gamma
plotEstimator(fit, "beta")
```

 - Aparentemente o modelo SSUR possui uma boa recuperação do verdadeira matriz indicadora latente $\boldsymbol \Gamma$ e da estrutura das respostas representada por $\mathcal G$.
 
---

## Análise dos Dados

```{r plt-graphs, echo=FALSE}
# estrutura estimada vs estrutura verdadeira
layout(matrix(1:2, ncol = 2))
plot(fit, estimator = "Gy", type = "graph")
plotGraph(Gy)
```


Utilizando o mesmo limiar, de $\hat{\mathcal G}$ limitado a 0.5, e $\hat{\boldsymbol \Gamma}$ limitado a 0.5, podemos visualizar a rede completa com as dez expressões gênicas e os 150 SNPs.

---

## Análise dos Dados

```{r plot-expr, echo = FALSE, fig.width=8, fig.height=5}
# estrutura entre X e Y
plot(fit, estimator = c("gamma", "Gy"), type = "network",
     name.predictors = "SNPs", name.responses = "Gene expression")
```

---

## Análise dos Dados

```{r plot-manh, echo = FALSE, , fig.width=10, fig.height=6}
plot(fit, estimator = "gamma", type = "Manhattan")
```

---

## Análise dos Dados

```{r plot-diag, echo = FALSE, fig.width=10, fig.height=6}
plot(fit, estimator = "logP", type = "diagnostics")
```

---

## Análise dos Dados

 - Os plots estilo Manhattan mostram as probabilidades de inclusão marginal (mPIP) dos SNPs (painel superior) e o número de expressões gênicas da resposta associado com cada SNP (painel inferior). O número de respostas é baseado em $\hat{\boldsymbol \Gamma}$ limitado a 0.5.

 - Observa-se nos plots de diagnóstico que as cadeias de Markov utilizadas aparentemente começam a amostrar da distribuição correta após aproximadamente 50.000 iterações.

 - Os painéis inferiores indicam que o logarítmo da distribuição a posteriori da variável indicadora latente $\boldsymbol \Gamma$ aparentemente estabilizou-se para a última metade das cadeias, após subtraído o burn-in.

---

## Análise dos Dados

Embora não tenhamos acesso direto às cadeias simuladas, podemos também visualizar a verossimilhança das outras matrizes estimadas pelo modelo.

```{r lik-est, echo = FALSE}
plotMCMCdiag(fit, HIWg = "lik")
```

---

## Análise dos Dados

É também possível utilizar o CPO para encontrar observações destoantes, como uma forma de validação cruzada do modelo com a amostra obtida. Temos algumas poucas observações abaixo do limiar.

```{r plot-cpo, echo = F}
# CPO
plotCPO(fit)
```

---

## Análise dos Dados

Finalizamos nossa análise com um sumário do modelo obtido.

.scroll-box-20[
```{r model-summary, echo = FALSE}
# sumario do modelo
summary(fit)
```
]

```{r detach, echo = FALSE}
detach(exampleEQTL)
```

---

## Conclusão

Neste relatório, procuramos apresentar os modelos para regressão e regularização partindo de uma abordagem Bayesiana, utilizamos o bacote `BayesSUR` para efetuar a regressão e seleção de modelos no conjunto de teste de exemplo apresentado por `r RefManageR::Citet(myBib,"BayesSUR2021")`.

Foram introduzidos brevemente os aspectos da modelagem da seleção de variáveis, assim como a recuperação das estruturas para identificar relacionamentos entre respostas multivariadas em preditores de alta dimensionalidade. 

Foi uma oportunidade muito valiosa de conhecer modelos estado-da-arte na área de biologia molecular, implementados de forma eficiente e bem documentada pelos autores do artigo que aqui apresentamos.

---

## Referências


```{r, results = "asis", echo=FALSE}
RefManageR::PrintBibliography(myBib)
```
