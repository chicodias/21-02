---
title: "SME0820 - Modelos de Regressão e Aprendizado Supervisionado I - Exercício I"
author:
  - Brenda da Silva Muniz 11811603
  - Francisco Rosa Dias de Miranda 4402962
  - Heitor Carvalho Pinheiro 11833351
  - Mônica Amaral Novelli 11810453
date: "Setembro 2021"
output: pdf_document
---

# Exercício 2

Queremos mostrar que os estimadores $\hat{\beta_0}$ e $\hat{\beta_1}$ são não enviesados.


$$E(\hat{\beta_1}) = E \left(\frac{S_{XY}}{S_{XX}}\right) =
E \left(\frac{\sum_{i=1}^n(x_i - \bar{x})y_i}{\sum_{i=1}^n(x_i - \bar{x})x_i} \right) =
\frac{\sum_{i=1}^n(x_i - \bar{x})E(y_i)}{\sum_{i=1}^n(x_i - \bar{x})x_i} $$

Temos que $y_i = \beta_0 + \beta_1x_i + \epsilon_i, \ i = 1,...,n$. Assim:

$$E(y_i) = E(\beta_0 + \beta_1x_i + \epsilon_i) = 
E(\beta_0) + E(\beta_1x_i) + E(\epsilon_i) = \beta_0 + \beta_1x_i$$

Voltando a expressão original, temos que:

$$E(\hat{\beta_1}) = \frac{\sum_{i=1}^n(x_i - \bar{x}) (\beta_0 + \beta_1x_i)}{\sum_{i=1}^n(x_i - \bar{x})x_i} = 
\frac{\beta_0 \sum_{i=1}^n(x_i - \bar{x})}{\sum_{i=1}^n(x_i - \bar{x})x_i} + \frac{\beta_1\sum_{i=1}^n(x_i - \bar{x}) x_i}{\sum_{i=1}^n(x_i - \bar{x})x_i} = \beta_1.$$

Procedendo de forma análoga para $\beta_0$, temos que:

$$E(\hat{\beta_0}) = E(\bar{y} - \hat{\beta_1}\bar{x}) =
E(\bar{y}) - \bar{x}E(\hat{\beta_1})$$

Resta-nos obter

$$E(\bar{y}) = E \left(\frac1n \sum_{i=1}^n y_i \right) =
\frac1n \sum_{i=1}^n E(y_i)  = 
\frac1n \sum_{i=1}^n (\beta_0 + \beta_1 x_i)  =$$

$$\frac{n\beta_0}n + \beta_1 \frac{\sum_{i=1}^n x_i}n = 
\beta_0 + \beta_1\bar{x}$$

Segue que:

$$E(\hat{\beta_0}) = E(\bar{y}) - \bar{x}E(\hat{\beta_1}) = 
(\beta_0 + \beta_1\bar{x}) - \beta_1\bar{x}= \beta_0$$

Portanto, $\hat{\beta_1}$ e $\hat{\beta_0}$ são não enviesados.

# Exercício 3

# Exercício 4

