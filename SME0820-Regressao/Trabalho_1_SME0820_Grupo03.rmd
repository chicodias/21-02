---
title: "SME0820 - Modelos de Regressão e Aprendizado Supervisionado I - Trabalho I"
author:
  - Brenda da Silva Muniz 11811603
  - Francisco Rosa Dias de Miranda 4402962
  - Heitor Carvalho Pinheiro 11833351-
  - Mônica Amaral Novelli 11810453
date: "Setembro 2021"
output: pdf_document
---

Neste trabalho, nosso objetivo é ajustar um modelo de regressão linear simples ao conjunto de dados fornecido, utilizando linguagem R. Para esta tarefa, descreveremos cada etapa de nosso *pipeline*.

O dataset B.3 contém dados sobre o rendimento de Gasolina, em milhas, de 32 automóveis diferentes. Ajuste o modelo de regressão linear simples que relaciona o rendimento da gasolina (y) (Milhas por litro) e a cilindrada do motor (x1) (polegadas cúbicas). Use sempre Significância: 99%.

Primeiramente, vamos carregar os módulos utilizados nesta análise. Caso não possua algum dos pacotes, utilize o comando `install_packages("Nome_do_pacote")`.


```{r pkgs, warning=FALSE,message = FALSE}
library(tidyverse)
library(ggpubr)
library(corrplot)
library(DataExplorer)
library(GGally)
library(knitr)
library(data.table)

```

Com os pacotes carregados em nosso ambiente, lemos o arquivo `.csv` disponibilizado colocando-o na mesma pasta de nosso projeto. Vamos inspecionar o que foi carregado com auxílio do comando `head()`, que exibe as 5 primeiras observações.

```{r read-load, warning=FALSE,message = FALSE}
dados <- read_csv("data-table-B3.csv", locale = locale(decimal_mark = ",")) %>% select(y, x1)

head(dados)
```
Vamos separar nossa base em treino e teste, aonde guardaremos 4 observações 

```{r}
set.seed(42)
smp <- sample(32, 4)

treino <- dados[-smp,]
teste <- dados[smp,]

y <- treino$y
x1 <- treino$x1

n <- length(y)

```

## Parte **a)**:
  - Descrição do banco de dados
  - Definição das variáveis
  - Análise exploratória inicial
```{r summary}
summary(dados)
```

  Com o comando **summary** verificamos as principais medidas descritivas para cada variável (feature) presente no nosso conjunto de dados. Temos 12 features e ajustaremos o modelo com base na feature x1.
  **Dimensão dos dados**

```{r dimdata}

dim(dados)

```
## Análise Exploratória Básica

**Gráfico da Dispersão entre x1 (cilindrada do motor) e y (rendimento da gasolina)**

```{r scatter}
ggplot(dados, aes(x=dados$x1, y = dados$y)) + geom_point() + #geom_smooth(method = "lm") +
  ggtitle("Cilíndradas Vs Rendimento") + xlab("cc/pol.c") + ylab("Rendimento (mi / L)") +
  theme_classic() +
  theme(plot.title = element_text(size = 20, hjust = .5))
```
Perceba que existe uma clara relação linear entre as duas variáveis, representada pela linha azul. Conforme as cilindradas do motor aumentam, o rendimento tende a diminuir.

```{r boxplot x1}
dados %>%
  ggplot(aes(x = "", y = dados$x1)) +
    geom_boxplot(color = "blue") +
    stat_summary(fun = mean, geom = "point", shape = 20, size = 5, color = "red", fill = "red") +
    geom_jitter(color="black", size=1, alpha=.9) +
    theme(plot.title = element_text(size = 15, hjust = .5)) +

    ggtitle("Boxplot da Variável (X1)") +
    xlab("") + ylab("Cilíndradas por Polegada Cúbica")


```
Podemos perceber a partir do boxplot acima e da função summary que 50% dos carros tem menos de 318 cilíndradas.

```{r}
dados %>%
  ggplot(aes( x=dados$y)) +
    geom_histogram(color = "black", fill = "lightblue", bins = 24) + # xlab("Rendimento") + ylab("Frequência") +
    geom_vline(aes(xintercept=mean(dados$y)), color = "red", linetype = "solid") +
    geom_vline(aes(xintercept=median(dados$y)), color = "black", linetype = "solid") +
    labs(title = "Histograma da variável Y (Rendimento do Motor em milhas por L)") +
    scale_x_continuous("Rendimento", limits = c(10,37,1), breaks = c(10:37)) +
    ylab("Frequência") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic()
```
O histograma acima representa a distribuição da variável y. As linhas verticais vermelha e preta representam, respectivamente, a média e a mediana.


```{r}
dados %>% filter(dados$y > 29.4)
```
A partir do histogrma e da tabela acima, concluimos que os 4 outliers referem-se aos valores: 30.4, 31.9, 34.7, e 36.5


Vamos verificar a distribuição da variável x1

```{r histx1}
dados %>%
  ggplot(aes( x=dados$x1)) +
    geom_histogram(color = "black", fill = "lightgreen", bins = 15) + # xlab("Rendimento") + ylab("Frequência") +
    geom_vline(aes(xintercept=mean(dados$x1)), color = "red", linetype = "solid") +
    geom_vline(aes(xintercept=median(dados$x1)), color = "black", linetype = "solid") +
    labs(title = "Histograma da variável X1 (Cilindradas por Polegada Cúbica)") +
    scale_x_continuous("Cilindradas", breaks = c(100,150,200,250,300,350,400,450,500)) +
    scale_y_continuous("Frequência", breaks = c(0:8), limits = c(0,6)) +
  #limits = c(85,500,1)) +
    ylab("Frequência") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic2()
```

## Parte **b)**:

Consultar e descrever brevemente os conceitos Data splitting, cross validation, overfitting, underfitting, missing data, encoding data.

1. Data Splitting: Data Splitting ou também “divisão de dados” é uma abordagem para proteger dados confidenciais de acesso não autorizado, criptografando os dados e armazenando diferentes partes de um arquivo em servidores diferentes. Quando os dados divididos são acessados, as partes são recuperadas, combinadas e descriptografadas.

2. Cross Validation: Cross Validation ou também “validação cruzada” é uma técnica muito utilizada para avaliar o desempenho de modelos de aprendizado de máquina. Consiste, basicamente, em particionar os dados em conjuntos, onde um conjunto é utilizado para treino e outro para teste e avaliação do desempenho do modelo. A utilização correta da técnica tem altas chances de detectar se um modelo está sobreajustado aos seus dados de treinamento, ou seja, sofrendo overfitting. Vale ressaltar que existem vários métodos de aplicação da validação cruzada.

3. Overfitting: Overfitting ou também "Sobreajuste" consiste na situação em que o modelo se ajusta bem demais ao conjunto de treinamento. Ou seja, nos dados de treinamento, em geral, a acurácia do modelo é muito alta (e, quando há 100% de acurácia dizemos que o modelo "memorizou" os dados). Isso ocorre pois além de aprender os detalhes dos dados o modelo também aprende os ruídos, o que prejudica sua capacidade de generalização no conjunto de teste. Em geral, quanto maior a complexidade do modelo mais propenso ao Overfitting ele se torna.

4. Underfitting: Já o Underfitting, por outro lado, refere-se ao problema em que o modelo não é capaz de modelar o conjunto de treinamento e nem generalizar para dados nunca vistos. Em geral, a solução reside no aumento da complexidade do modelo ou a troca do algoritmo.

5. Missing data: Missing data, muitas vezes referido como missing values (com tradução literal: valores que faltam), é um conceito utilizado para quando alguma(s) observação(ões) no conjunto de dados está(ão) vazia(s), causando ambuiguidade e falta de precisão para a análise do mesmo.
Na análise multivariada, temos uma relação proporcional da quantidade de variáveis a serem relacionadas com a falta de rigor causada pelos missing values.

6. Encoding data: Encoding data (de tradução literal: dados codificados) é o nome dado para o processo de converter dados para um formato específico, assegurando sua transmissão e otimizando o modelo. Seu processo inverso - ou seja, a decodificação - refere-se a extrair as informações da forma convertida.

## Parte **c)**:

  1. Calcular $S_{XX}$,$S_{YY}$ e $S_{XY}$


Calculando o valor de $S_{xx}$

$$S_{XX} =  \sum_{i=1}^n (x -\bar{x})^2$$

```{r}
xbarra=mean(x1)
x1-xbarra
(x1-xbarra)^2
Sxx=sum((x1-xbarra)^2)
```


### Calculando o valor de $S_{yy}$

$$S_{YY} =  \sum_{i=1}^n (y - \bar{y})^2$$

```{r}
ybarra=mean(y)
y-ybarra
(y-ybarra)^2
Syy=sum((y-ybarra)^2)
```

### Calculando o valor de $S_{xy}$

$$S_{XY} =  \sum_{i=1}^n (x - \bar{x})(y - \bar{y})$$

```{r}
Sxy=sum((x1-xbarra)*(y-ybarra))
cbind(Sxx,Syy,Sxy)
```

  2. Ajustar um modelo de regressão linear simples, apresentar a estimativa de $\beta_0, \beta_1$ e $\sigma^2$ e fazer um gráfico com a reta ajustada

## Estimacao dos parametros

$$\beta_1 = S_{XY}/S_{XX}$$

### Calculando o valor do coeficiente angular $\beta_1$

```{r}
b1_est <- Sxy/Sxx
```

### Calculando o valor do intercepto $\beta_0$

```{r}
b0_est <- mean(y) - b1_est*mean(x1)
```

### Calculando o estimador de $\sigma^2$ não viesado.

Tal estimador é obtido através da soma do quadrado dos resíduos, definido pela variável *QMres*, de modo que:

```{r}
# Soma do quadrado da regressão:
SQreg <- b1_est*Sxy

# Soma do quadrado total:
SQtotal <- sum((y-mean(y))^2)

# Diferença entre a soma do quadrado da regressão e a soma do quadrado total:
SQres <- SQtotal - SQreg

# Soma do quadrado dos resíduos:
QMres <- SQres/(n-2)

```

```{r}

dados %>% ggplot(aes(x= x1, y= y)) + geom_point() +
  geom_smooth(method='lm', formula= y~x)

#Arredondando b0 e b1
round(b0_est, 4)
round(b1_est, 4)


```
Consequentemente, a reta ajustada é:
$$\widehat{Y}_i=1224.043-0.7769X_i$$


  3. Calcule o valor dos $\hat{Y}$ e o valor dos resíduos para seu modelo, resumo e histograma dos resíduos, e faça uma análise da distribuição destes.

  O cálculo de $\hat{Y}$ pode ser realizado utilizando o modelo de regressão linear simples, em que a variabilidade de interesse é dada em função de uma única covariável - no caso, *x1*. No R, podemos expressar $\hat{Y}$ como sendo:

```{r}
y_pred <-  b0_est + b1_est*x1
```

Os resíduos se dão pelo desvio entre as observações e os valores preditos, sendo uma medida de variabilidade na variável resposta onde qualquer desvio relativo a suposição dos erros deveria aparecer. Analisá-los nos permite um discernimento maior em relação a quão adequado é o modelo. Fazendo uso do cálculo de *y_pred* feito anteriormente, salvamos nossos resíduos em uma variável *res* abaixo.

```{r}
res <- y - y_pred
```

Utilizando o comando *summary*, podemos observar as principais medidas descritivas da variável, o que nos auxilia para a análise da mesma.
  
```{r}
summary(res)
```
  
Também podemos construir um histograma, que facilitará a visualização do comportamento dos resíduos.

```{r}
# Histograma
n_res <- length(res)

ggplot(dados, aes(x = res)) +
  ylab("Frequência") +
  geom_histogram(color = "black", fill = "#FF69B4", bins=12)+
  labs(title = "Histograma dos resíduos")+
  scale_x_continuous("Resíduos", limits = c(-8,8,1), breaks = c(-8:8))+
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_classic()
```

Desse modo, temos que a análise dos resíduos é --------

  4. testes de hipotese para $\beta_0$ e $\beta_1$

Para realizarmos nossos testes de hipóteses, é necessário o estimador do parâmetro $\sigma^2$ do nosso modelo, uma vez que ele não é dado. Tal estimador não viesado é obtido através da soma do quadrado dos resíduos, definido pela variável *QMres*, calculada no item 3 de modo que:

```{r}
# Soma do quadrado da regressão:
SQreg <- b1_est*Sxy

# Soma do quadrado total:
SQtotal <- sum((y-mean(y))^2)

# Diferença entre a soma do quadrado da regressão e a soma do quadrado total:
SQres <- SQtotal - SQreg

# Soma do quadrado dos resíduos:
QMres <- SQres/(n-2)

```

A partir disso, podemos prosseguir com nossos testes de hipóteses para $\beta_1$ e $\beta_0$, com decisão de rejeitar ou não $H_0$, uma vez que este representa o parâmetro se igualar a 0 estatisticamente caso não seja rejeitado, descrevendo a significância da contribuição do mesmo. 
  
  * Testagem se $\beta_1 = 0$:

$\beta_1$ possuí distribuição Normal com média $\beta_1$ e variância $\sigma^2/S_{xx}$, com isso, definimos:

```{r}
dp_b1 <- (sqrt(QMres/Sxx))
t0_b1 <- b1_est/dp_b1
```

  Pelo enunciado, é dado que $\alpha= 5\%$. Se H0 não for rejeitado, temos que $\beta_1$ é estatisticamente igual a zero. 
  A partir disso, definimos $\alpha$ e dois quantis, de modo que *t1* é o quantil $\frac{\alpha}{2}$ da distribuicao $t$ com grau de liberdade $ n -2$, enquanto *t2* é o quantil $\frac{1-\alpha}{2}$ da distribuicao $t$ com grau de liberdade $n -2$.
  Com esses dados, podemos construir nosso programa de decisão que retornará caso $H_0$ seja rejeitado.
  
```{r}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)

if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}
```
Para $\alpha= 1\%$:
  
```{r}
alpha <- 0.01
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)

if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}
```


Realizando o teste, temos que H0 é rejeitado, logo, $\beta_1$ é diferente de zero.

  * Testagem se $\beta_0 = 0$:

  $\beta_0$ possuí distribuição Normal com média $\beta_0$ e variância $\sigma^2((\frac{1}{n})+\frac{\bar{X}}{S_{xx}}))$, com isso, definimos:

```{r}
dp_b0 <- (sqrt( QMres *( (1/n) + (mean(x1))^2/Sxx )))

t0_b0 <- b0_est/dp_b0
```

  Em um processo semelhante à testagem de $\beta_1$, com $\alpha$= 5% e os mesmos quantis, também é possível a construção de nossa função de decisão. Se H0 não for rejeitado, temos que $\beta_0$ é estatisticamente igual a zero.

```{r}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)

if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}

```
Para $\alpha= 0.01$

```{r}
alpha <- 0.01
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)

if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}

```

Realizando o teste, temos que H0 é rejeitado, logo, $\beta_0$ é diferente de zero.


  5. intervalos de confiança

## ***Intervalos de Confiança***

Intervalos de Confiança para $(\beta_0,\beta_1,\sigma^2)$ e $E(Y)$.

***Calculando intervalo de Confiança para $\beta_1$***
```{r icbeta1}
b1_min <- beta1est-t2*dp_b1
b1_max <- beta1est-t1*dp_b1
IC_b1_est <- cbind(b1_min, b1_max)
IC_b1_est
```
 (y) (Milhas por litro) e a  (x1) (polegadas cúbicas)

**Interpretação:** Cada incremento em polegada cúbica na cilindrada do motor
aumenta o consumo em milhas por litro em -0.0473, com uma margem de erro de aproximadamente 0.009
para mais ou para menos.

***Calculando intervalo de Confiança para $\beta_0$***
```{r icbeta0}
b0_min <- beta0est-t2*dp_b0
b0_max <- beta0est-t1*dp_b0
IC_b0_est <- cbind(b0_min, b0_max)
IC_b0_est
```



***Calculando intervalo de confiança para $\sigma^2$***

Lembrado que $SQres/\sigma^2$ tem Distribuição
qui-quadrado com $(n-2)$ G.L.
```{r icsigmaone}
t1_sig <- qchisq(alpha/2, n-2)
t2_sig <- qchisq(1-alpha/2,n-2)
```


```{r icsigmatwo}
sig_min <- SQres/t2_sig
sig_max <- SQres/t1_sig
```


```{r icsigmathree}
IC_sig_est <- cbind(sig_min, sig_max)
IC_sig_est
```

**Calculando intervalo de confiança para a esperança de y**

(valor medio da variavel resposta para um valor
particular da cov., MIy|X0).

**Lembrando:**

1. O valor médio da variável resposta é dado um $X_0$.
2. $\overline{Y}$ tem Distribuição Normal.
com média $\beta_0+\beta_1*\overline{X}$ e variância $\sigma^2/n$.
3. $\beta_1$ tem Distribuição Normal com média $\beta_1$ e variância
$\sigma^2/Sxx$.
4. A Esperança de $Y|X_0$ é Normal.
5. a Variância de $MIy|X_0$ é $\sigma^2*(1/n + ((X_0-\overline{X}^2)/Sxx)$,
 $t_1 =$ quantil da dist. $t(\alpha/2,n-2)$,
 $t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$,
 $\alpha = 0,05$.

**Exemplo:**
Nesse exemplo usaremos $X_0$ como sendo o proprio $\overline{X}$.
```{r x0exbarra}
X0 <- mean(x1) # poderia ser outro valor

v_medio <- (mean(y)+beta1est* (X0-mean(x1)) )

auxiliar <- sqrt(QMres*(1/n + (X0 - mean(x1)) /Sxx ))
```

**Intervalo De Confiança**
```{r icmedio}
v_medio_min <- v_medio - t2*auxiliar
v_medio_max <- v_medio - t1*auxiliar

IC_v_medio <- cbind(v_medio_min, v_medio_max)
IC_v_medio
```

E se quisessemos predizer a mortalidade baseado em um novo valor
da variavel explicativa utilizada. Qual seria o intervalo
que em $95\%$ das vezes iria conter o verdadeiro valor predito
considerando a nova informação de $x_1$ ?
(Ou seja, qual seria o Intervalo de Confiança para o valor
predito de $Y$ baseado no novo valor da variavèl $x_1$ com $95\%$
de confiança).

## ***Intervalo de predição***

O intervalo de predição para até $5$ valores diferentes de $X_0$.

***Intervalos de predição***

*Lembrando:*

$Y_0$_est $= \beta_0$_est $+ \beta_1$_est$\ *\ x_1$_novo.

$Y_0$ e $Y_0$_est são independentes.

$t_1 =$ quantil da dist. $t(\alpha/2,n-2)$.

$t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$.

$\alpha = 0,05$.

***Exemplo***
```{r exem1}
x1_novo <- 12  
#x1_novo <- c(12,20,48,51,57,62)
Y0_est <- beta0est + beta1est*x1_novo
auxiliar_y0 <- sqrt(QMres*(1+ 1/n + (x1_novo - mean(x1)) /Sxx ))
```

```{r exey}
Y0_est_min <- Y0_est - t2*auxiliar_y0
Y0_est_max <- Y0_est - t1*auxiliar_y0
```

```{r ixexem}
IC_Y0_est <- cbind(Y0_est_min, Y0_est_max)
IC_Y0_est
```


## ***Análise de Variâcia***

A Análise de Variâcia com todos os valores (Graus de Liberdade, SQTotal, SQRes, SQReg, QMRes, QMReg e F).

***ANOVA***

 Teria outra forma de testarmos a significancia da regressão ?
 Sim! Outra forma seria pela Análise de Variância (ANOVA), nesse
 caso testariamos se $\beta_1 = 0$.

**Soma do quadrado da Regressão**
```{r saqreganova}
SQreg <- beta1est*Sxy
SQreg
```

**Soma do quadrado total**
```{r asqtotalanova}
SQtotal <- sum((y-mean(y))^2)
SQtotal
```

**Soma do quadrado do resíduo**
```{r asqresanova}
SQres <- sum((y-mean(y))^2) - beta1est*Sxy
SQres
```

```{r sqresanova}
QMreg <- SQreg
QMreg
```

**Lembre-se que QMres eh o estimador de sigma^2 e QMres=SQres/(n-2)**
```{r faanova}
F_0 <- QMreg/QMres
F_0
```

**Quantil da Distribuição F-Snedecor**
```{r f1aanova}
f1 <- pf(F_0, df1 = 1, df2 = n-2, lower.tail = F)
f1
```

```{r descisaaoanova}
if(F_0 > f1){
  cat("Rejeita-se H0")
}
```

**ou poderiamos ter calculado**
```{r alternaanova}
f1.2 <- pf(t0_b1^2, df1 = 1, df2 = n-2, lower.tail = F)
```

```{r desalteraanova}
if(t0_b1^2 > f1.2){
  cat("Rejeita-se H0")
}
```

***Anova usando funções do R***
```{r funanovar}
Anovamodel <- aov(y ~ x1, data = dados)
Anovamodel
```

```{r resumofunanovar}
summary(Anovamodel)
```

***Normalidade dos resíduos***
```{r normalidadtestresd}
shapiro.test(resid(Anovamodel))
```

A hipótese nula do Teste de Shapiro-Wilk é de que não há diferença entre a nossa distribuição dos dados e a distribuição normal. O valor-p maior do que 0.05 nos dá uma confiança estatística para afirmar que as distribuição dos nossos resíduos não difere da distribuição normal.

Dessa forma nossos dados satisfazem todas as premissas da ANOVA e portanto, o resultado da nossa ANOVA são válidos.
