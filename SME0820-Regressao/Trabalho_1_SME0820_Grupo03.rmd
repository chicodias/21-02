---
title: "SME0820 - Modelos de Regressão e Aprendizado Supervisionado I - Trabalho I"
author: 
  - Brenda da Silva Muniz 11811603
  - Francisco Rosa Dias de Miranda 4402962
  - Heitor Carvalho Pinheiro 11833351-
  - Mônica Amaral Novelli 11810453
date: "Setembro 2021"
output: pdf_document
---

bla
Neste trabalho, nosso objetivo é ajustar um modelo de regressão linear simples ao conjunto de dados fornecido, utilizando linguagem R. Para esta tarefa, descreveremos cada etapa de nosso *pipeline*.

O dataset B.3 contém dados sobre o rendimento de Gasolina, em milhas, de 32 automóveis diferentes. Ajuste o modelo de regressão linear simples que relaciona o rendimento da gasolina (y) (Milhas por litro) e a cilindrada do motor (x1) (polegadas cúbicas). 

Primeiramente, vamos carregar os módulos utilizados nesta análise. Caso não possua algum dos pacotes, utilize o comando `install_packages("Nome_do_pacote")`.


```{r pkgs, warning=FALSE,message = FALSE}
library(tidyverse)
library(ggpubr)
library(corrplot)
library(DataExplorer)
library(GGally)
library(knitr)
library(data.table)

```

Com os pacotes carregados em nosso ambiente, lemos o arquivo `.csv` disponibilizado colocando-o na mesma pasta de nosso projeto. Vamos inspecionar o que foi carregado com auxílio do comando `head()`, que exibe as 5 primeiras observações.

```{r read-load, warning=FALSE,message = FALSE}
dados <- read_csv("data-table-B3.csv", locale = locale(decimal_mark = ","))

head(dados)
```
## Parte **a)**: 
  - Descrição do banco de dados
  - Definição das variáveis
  - Análise exploratória inicial
  

```{r pairplot, fig.cap = "Correlograma entre as variáveis", warning=FALSE}

ggcorr(dados, geom = "circle")

```
bla

  - Graficos de dispersão $Y$ versus $X_i$, $i = 1, ..., 11.$
  
```{r scatterplot, fig.cap = "Gráfico de Dispersão de Y com as demais variáveis"}

dados %>%
  pivot_longer(cols = !"y") %>%
  ggplot(aes(y = y)) +
    geom_point(aes(x = value)) +
    facet_wrap(~name, scales = "free_x") + theme_pubclean()

```
  - Interpretação de cada gráfico
  
## Parte **b)**:

Consultar e descrever brevemente os conceitos Data splitting, cross validation, overfitting, underfitting, missing data, encoding data.

## Parte **c)**:
  1. Calcular $S_{XX}$,$S_{YY}$ e $S_{XY}$
  2. Ajustar um modelo de regressão linear simples, apresentar a estimativa de $\beta_0, \beta_1$ e $\sigma^2$ e fazer um gráfico com a reta ajustada
  
```{r}
fit <- lm(y ~ x1, data = dados, )

summary(fit)
anova(fit)
dados %>% ggplot(aes(x= x1, y= y)) + geom_point() +
    geom_smooth(method='lm', formula= y~x)

```
  
  
  3. Calcule o valor dos $\hat{Y}$ e o valor dos resíduos para seu modelo, resumo e histograma dos resíduos, e faça uma análise da distribuição destes.
  4. testes de hipotese para $\beta_0$ e $\beta_1$
  
  5. intervalos de confiança
```{r}
confint(fit, level = 0.99)
```
  
  
  6. intervalos de predição
```{r}
#predict(fit, newdata = new.dat, interval = 'prediction')
```
  

algumas variaveis que precisamos
```{r}
y <- dados$y
x1 <- dados$x1
n <- length(y)
```

# Galera daqui ppra baixo só colei o markdown do danilo


Calcule $Sxx, Syy, Sxy$.

Note que as expressões para $Sxx, Syy$ e $Sxy$ foram apresentadas na Aula $3$ e são dadas por:

$Sxx=\sum_{i=1}^n(X_i-\overline{X})^2=\sum_{i=1}^nX_i^2-n\overline{X}^2$,

$Syy=\sum_{i=1}^n(Y_i-\overline{Y})^2=\sum_{i=1}^nY_i^2-n\overline{Y}^2$,

$Sxy=\sum_{i=1}^n(X_i-\overline{X})(Y_i-\overline{Y})=\sum_{i=1}^n(X_iY_i)-n\overline{X}\overline{Y}=\sum_{i=1}^n(X_i-\overline{X})Y_i$

Vamos cacular primeiramente $\overline{X}$, logo subtraimos ele da variavél, elevamos ao quadrado cada termo e sumarmos para obter.   
```{r Sxx}
xbarra=mean(x1)
x1-xbarra
(x1-xbarra)^2
Sxx=sum((x1-xbarra)^2)
Sxx
```

```{r Syy}
ybarra=mean(y)
y-ybarra
(y-ybarra)^2
Syy=sum((y-ybarra)^2)
Syy
```

```{r Sxy}
Sxy=sum((x1-xbarra)*(y-ybarra))
Sxy
```

```{r Ssumsresults}
cbind(Sxx,Syy,Sxy)
```




##Ajuste do modelo de regressão linear simples e gráfico  da reta ajustada 

Note que na aula $3$ temos feito passo a passo do ajuste do modelos mediante o método de minimos quadrados (ajustar um modelo significa mesmo estimar seus parâmetros). Nosso modelo liear simples é da forma:
$$Y=\beta_0+\beta_1X+\xi$$ onde aplicando a técnica de mínimos quadrados teremos estimadores para nossos parâmetros dados pelas seguintes expressões:
$\widehat{\beta_0}=\overline{Y}-\widehat{\beta_1}\overline{X}\\\widehat{\beta_1}=\dfrac{Sxy}{Sxx}$. Portanto,

```{r betasest}
beta1est=(Sxy)/(Sxx)
beta0est=ybarra-(beta1est*xbarra)
cbind(beta0est,beta1est)
```


**Gráfico Reta Ajustada**
```{r grafajuste}
plot(x1,y , #ylim = c(750,1150), xlim = c(9,65),
     main = expression(paste("Reta ajustada com ", 
                             hat(beta)[0],"=821,7546", 
                             " e ", hat(beta)[1],"=3,174")),
     xlab = "Precip", ylab = "Mortalidade")
curve(beta0est + beta1est*x, add = T, col = 'red')
```

Consequentemente, a reta ajustada é
$$\widehat{Y}_i=821.7546+3.174002*X_i$$

***Estimando $\sigma^2$***

O estimador de $\sigma^2$ não viesado eh obtido pelo quadrado médio do resíduo (QMres) apresentado passo a passo na aula $5$. Para termos QMreg precisamos do SQres.

**SQreg**
```{r sqreg}
SQreg <- beta1est*Sxy
SQreg
```

**SQtotal**
```{r sqtotal}
SQtotal <- sum((y-mean(y))^2)
SQtotal
```

**SQRes = SQtotal - SQreg**
```{r sqres}
SQres <- SQtotal - SQreg
SQres
```

**MQres**
```{r mqres}
#estimador nao viesado de sigma^2
QMres <- SQres/(n-2)
SigmaQuadradoEst<-QMres
SigmaQuadradoEst
```


```{r estimativ}
#Estimativas para Beta0, Beta1 e Sigma^2
cbind(beta0est, beta1est, SigmaQuadradoEst)

```



## Resíduos 

O valor dos $\widehat{Y}$'s e o valor dos resíduos para o seu modelo, faça um resumo e Histograma dos resíduos e faça análise da distribuição destes. 

Para sabermos os resíduos do nosso modelo vamos calcular o valor predito primeiro.

```{r valpredito}
# valor predito
y_pred <- beta0est + beta1est*x1
```

```{r ypredi}
# Ou ainda 
y_pred <- mean(y) + beta1est*(x1 - mean(x1))
```

***Resíduos***
```{r residuos}
res <- y - y_pred
res
summary(res)
```
***Histograma dos Resíduos***
```{r historesiduos}
hist(res, main = "Histograma dos Resíduos", col = "green",
    # xlim = c(-151, 130), ylim = c(0, 30), 
     ylab = "Frequencia", xlab = "Resíduos")
```  
```{r qqplotresidu}
qqnorm(res)
qqline(res, col = "blue")
```


## Teste de Hipótese 

Obteremos os teste de hipóteses para $\beta_0$ e $\beta_1$ com a decisão de rejeitar ou não $H_0$.

Sera que $\beta_0 = 0$ estatísticamente? E sera que $\beta_1=0$ estatísticamente?. Para isso precisamos calcular o estimador de $\sigma^2$ (Utilizando $\alpha=5\%$).

***Teste de Hipótese para $\beta_1$***

Testando se $\beta_1 = 0$, Lembrando que $\beta_1$ estimado tem distribuição Normal com media $\beta_1$ e variância$=(\sigma^2/Sxx)$.

Como nâo temos o valor de $\sigma^2$ temos que estima-lo. 

$H_0: \beta_1 = 0$  vs $H_1: \beta_1$ não eh zero $(\beta_1\neq 0)$.

```{r estimabetas}
dp_b1 <- (sqrt(QMres/Sxx))
t0_b1 <- beta1est/dp_b1
```


Rejeitamos $H_0$ se t0_b1 $< t_1$ ou t0_b1 $> t_2$, em que $t_1$ eh o quantil $\alpha/2$ da Distribuição $t$ com $n-2$ G.L. e $t_2$ eh o quantil $1-\alpha/2$ da Distribuição $t$ com $n-2$ G.L. útilizando $\alpha = 5\%$.

```{r quantilst}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)
```

*Regra de Decisão*
```{r decisao}
if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}
```


Como podemos ver pelo teste, rejeitamos $H_0$. Ou seja, rejeitamos a hípotese que o valor do coeficiente $\beta_1 = 0$. 

***Teste de Hipótese para $\beta_0$***

Testando se $\beta_0 = 0$. Lembrando que $\beta_0$ estimado tem Distribuição Normal com média $\beta_0$ e variância$=(\sigma^2*((1/n)+ \overline{X}/Sxx))$ como não temos o valor de $\sigma^2$ temos que estima-lo. 

$H_0: \beta_0 = 0$  vs $H_1: \beta_0$ não eh zero $(\beta_0\neq 0)$
```{r nvotest}
dp_b0 <- (sqrt( QMres *( (1/n) + (mean(x1))^2/Sxx )))

t0_b0 <- beta0est/dp_b0
```

Rejeitamos $H_0$ se t0_b0 $< t_1$ ou t0_b0 $>t_2$, em que 
$t_1$ eh o quantil $\alpha/2$ da Distribuição $t$ com $(n-2)$ G.L.
$t_2$ eh o quantil $1-\alpha/2$ da Distribuicao $t$ com $(n-2)$ G.L.
útilizando $\alpha = 5\%$

```{r quantts}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)
```

*Regra de Decisão*
```{r desnov}
if(t0_b0 < t1 || t0_b0>t2){
  cat("Rejeita-se H0")
}
```


Como podemos ver pelo teste, rejeitamos $H_0$. 
Ou seja, rejeitamos a hípotese que o valor do 
intercepto $\beta_0 = 0$.


#**vou editar a partir daqui**

  
## ***Intervalos de Confiança*** 

Intervalos de Confiança para $(\beta_0,\beta_1,\sigma^2)$ e $E(Y)$.

***Calculando intervalo de Confiança para $\beta_1$***
```{r icbeta1}
b1_min <- beta1est-t2*dp_b1
b1_max <- beta1est-t1*dp_b1
IC_b1_est <- cbind(b1_min, b1_max)
IC_b1_est
```
 (y) (Milhas por litro) e a  (x1) (polegadas cúbicas)

**Interpretação:** Cada incremento em polegada cúbica na cilindrada do motor
aumenta o consumo em milhas por litro em -0.0473, com uma margem de erro de aproximadamente 0.009
para mais ou para menos.

***Calculando intervalo de Confiança para $\beta_0$***
```{r icbeta0}
b0_min <- beta0est-t2*dp_b0
b0_max <- beta0est-t1*dp_b0
IC_b0_est <- cbind(b0_min, b0_max)
IC_b0_est
```



***Calculando intervalo de confiança para $\sigma^2$***

Lembrado que $SQres/\sigma^2$ tem Distribuição
qui-quadrado com $(n-2)$ G.L.
```{r icsigmaone}
t1_sig <- qchisq(alpha/2, n-2)
t2_sig <- qchisq(1-alpha/2,n-2)
```


```{r icsigmatwo}
sig_min <- SQres/t2_sig
sig_max <- SQres/t1_sig
```


```{r icsigmathree}
IC_sig_est <- cbind(sig_min, sig_max)
IC_sig_est
```

**Calculando intervalo de confiança para a esperança de y**

(valor medio da variavel resposta para um valor 
particular da cov., MIy|X0).

**Lembrando:**

1. O valor médio da variavél resposta é dado um $X_0$. 
2. $\overline{Y}$ tem Distribuição Normal. 
com média $\beta_0+\beta_1*\overline{X}$ e variância $\sigma^2/n$.
3. $\beta_1$ tem Distribuição Normal com média $\beta_1$ e variância
$\sigma^2/Sxx$. 
4. A Esperança de $Y|X_0$ é Normal.
5. a Variância de $MIy|X_0$ é $\sigma^2*(1/n + ((X_0-\overline{X}^2)/Sxx)$,
 $t_1 =$ quantil da dist. $t(\alpha/2,n-2)$,
 $t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$,
 $\alpha = 0,05$.

**Exemplo:**
Nesse exemplo usaremos $X_0$ como sendo o proprio $\overline{X}$.
```{r x0exbarra}
X0 <- mean(x1) # poderia ser outro valor

v_medio <- (mean(y)+beta1est* (X0-mean(x1)) )

auxiliar <- sqrt(QMres*(1/n + (X0 - mean(x1)) /Sxx ))
```

**Intervalo De Confiança**
```{r icmedio}
v_medio_min <- v_medio - t2*auxiliar
v_medio_max <- v_medio - t1*auxiliar

IC_v_medio <- cbind(v_medio_min, v_medio_max)
IC_v_medio
```

E se quisessemos predizer a mortalidade baseado em um novo valor
da variavel explicativa utilizada. Qual seria o intervalo 
que em $95\%$ das vezes iria conter o verdadeiro valor predito
considerando a nova informação de $x_1$ ?
(Ou seja, qual seria o Intervalo de Confiança para o valor 
predito de $Y$ baseado no novo valor da variavèl $x_1$ com $95\%$ 
de confiança).

## ***Intervalo de predição*** 

O intervalo de predição para até $5$ valores diferentes de $X_0$.

***Intervalos de predição***

*Lembrando:*

$Y_0$_est $= \beta_0$_est $+ \beta_1$_est$\ *\ x_1$_novo.

$Y_0$ e $Y_0$_est são independentes.

$t_1 =$ quantil da dist. $t(\alpha/2,n-2)$.

$t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$.

$\alpha = 0,05$.

***Exemplo***
```{r exem1}
x1_novo <- 12  
#x1_novo <- c(12,20,48,51,57,62)
Y0_est <- beta0est + beta1est*x1_novo
auxiliar_y0 <- sqrt(QMres*(1+ 1/n + (x1_novo - mean(x1)) /Sxx ))
```

```{r exey}
Y0_est_min <- Y0_est - t2*auxiliar_y0
Y0_est_max <- Y0_est - t1*auxiliar_y0
```

```{r ixexem}
IC_Y0_est <- cbind(Y0_est_min, Y0_est_max)
IC_Y0_est
```


## ***Análise de Variâcia*** 

A Análise de Variâcia com todos os valores (Graus de Liberdade, SQTotal, SQRes, SQReg, QMRes, QMReg e F).

***ANOVA***

 Teria outra forma de testarmos a significancia da regressão ?
 Sim! Outra forma seria pela Análise de Variância (ANOVA), nesse 
 caso testariamos se $\beta_1 = 0$.

**Soma do quadrado da Regressão**
```{r saqreganova}
SQreg <- beta1est*Sxy
SQreg
```

**Soma do quadrado total**
```{r asqtotalanova}
SQtotal <- sum((y-mean(y))^2)
SQtotal
```

**Soma do quadrado do resíduo**
```{r asqresanova}
SQres <- sum((y-mean(y))^2) - beta1est*Sxy
SQres
```

```{r sqresanova}
QMreg <- SQreg
QMreg
```

**Lembre-se que QMres eh o estimador de sigma^2 e QMres=SQres/(n-2)**
```{r faanova}
F_0 <- QMreg/QMres 
F_0
```

**Quantil da Distribuição F-Snedecor**
```{r f1aanova}
f1 <- pf(F_0, df1 = 1, df2 = n-2, lower.tail = F)
f1
```

```{r descisaaoanova}
if(F_0 > f1){
  cat("Rejeita-se H0")
}
```

**ou poderiamos ter calculado**
```{r alternaanova}
f1.2 <- pf(t0_b1^2, df1 = 1, df2 = n-2, lower.tail = F)
```

```{r desalteraanova}
if(t0_b1^2 > f1.2){
  cat("Rejeita-se H0")
}
```

***Anova usando funções do R***
```{r funanovar}
Anovamodel <- aov(y ~ x1, data = dados)
Anovamodel
```

```{r resumofunanovar}
summary(Anovamodel)
```

***Normalidade dos resíduos***
```{r normalidadtestresd}
shapiro.test(resid(Anovamodel))
```

A hipótese nula do Teste de Shapiro-Wilk é de que não há diferença entre a nossa distribuição dos dados e a distribuição normal. O valor-p maior do que 0.05 nos dá uma confiança estatística para afirmar que as distribuição dos nossos resíduos não difere da distribuição normal.

Dessa forma nossos dados satisfazem todas as premissas da ANOVA e portanto, o resultado da nossa ANOVA são válidos.



