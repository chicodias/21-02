---
title: "Aula Lab 1"
author: "Daniel Camilo Fuentes Guzman"
date: "17/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




Primeiramente vamos verificar o diretorio de trabalho atual, vamos selecionar o diretorio de trabalho desejado e logo carregar o Dataset asignado para as atividades.

## Diretorio de Trabalho

***Verificando o Diretorio de Trabalho***
```{r Dir}
getwd()
```


***Selecionando Diretorio de Trabalho***
```{r Diretorio}
setwd('C:/Users/camig/OneDrive/Documentos/R/Gabarito tarefa 1')
```



***Carregando o Dataset***
  
```{r dados}
data <- read.table("data-aula1-lab.csv", header = TRUE, sep = ";", dec = ",")
head(data)
```

Note que este dataset corresponde a McDonald e Ayers (1978) onde  apresentam dados de um estudo anterior que examinou a possível ligação entre poluição do ar e mortalidade. A descrição dos dados é a seguinte:

**MORT** = mortalidade total ajustada por idade por todas as causas, em mortes por $100.000$ habitantes.

**PRECIP** = precipitação média anual. (em polegadas).

**EDUC** = número médio de anos escolares concluídos para pessoas de $25$ anos ou mais.

**NONWHITE** = porcentagem da população de $1960$ que não é branca.

**NOX** = potencial relativo de poluição de óxidos de nitrogênio.

**SO2** = potencial relativo de poluição do dióxido de enxofre.     "Potencial relativo de poluição" é o produto das toneladas emitidas cada dia por quilômetro quadrado eum fator de correção das dimensões e exposição o SMSA.

```{r resumodados}
summary(data)
```
Agora precisarmos definir no data set qual coluna vai corresponder a nosso target  ou variavél resposta $(Y)$ e qual vai ser nosso preditor linear ou variavél explicativa $(X)$. Nesse caso, 
```{r features}
y <- data$MORT
x1 <- data$PRECIP
dados <- data.frame(cbind(x1, y))
```

```{r dimdata}
dim(data)
dimfeature=c(dim(data))
n=dimfeature[1]
n
```

# Gráficos 
***Gráfico de Dispersão Mortalidade vs precip***
```{r gradispervaryex}
plot(x1,y, main = "Gráfico de dispersão \n Mortalidade vs X1", 
     ylim = c(750,1150), xlim = c(9,65))
```

***Box-plot de y***
```{r boxploty}
boxplot(dados$y, main = "Box plot da variavel y", col = "red")
```

***Box-plot de x1***
```{r boxplotx1}
boxplot(dados$x1, main = "Box plot da variavel x1", col = "blue")
```


***Histograma de y***
```{r histogy}
hist(y, main = "Histograma da variável Mortalidade", col = "red",
     xlim = c(700, 1200), ylim = c(0, 20), 
     ylab = "Frequencia", xlab = "Mortes")
```     

***Histograma de x1***
```{r histogx1}
hist(x1, main = "Histograma da variável precipitação média anual", col = "blue",
     xlim = c(0, 70), ylim = c(0, 40), 
     ylab = "Frequencia", xlab = "Mortes")
```  




Calcule $Sxx, Syy, Sxy$.

Note que as expressões para $Sxx, Syy$ e $Sxy$ foram apresentadas na Aula $3$ e são dadas por:

$Sxx=\sum_{i=1}^n(X_i-\overline{X})^2=\sum_{i=1}^nX_i^2-n\overline{X}^2$,

$Syy=\sum_{i=1}^n(Y_i-\overline{Y})^2=\sum_{i=1}^nY_i^2-n\overline{Y}^2$,

$Sxy=\sum_{i=1}^n(X_i-\overline{X})(Y_i-\overline{Y})=\sum_{i=1}^n(X_iY_i)-n\overline{X}\overline{Y}=\sum_{i=1}^n(X_i-\overline{X})Y_i$

Vamos cacular primeiramente $\overline{X}$, logo subtraimos ele da variavél, elevamos ao quadrado cada termo e sumarmos para obter.   
```{r Sxx}
xbarra=mean(x1)
x1-xbarra
(x1-xbarra)^2
Sxx=sum((x1-xbarra)^2)
Sxx
```

```{r Syy}
ybarra=mean(y)
y-ybarra
(y-ybarra)^2
Syy=sum((y-ybarra)^2)
Syy
```

```{r Sxy}
Sxy=sum((x1-xbarra)*(y-ybarra))
Sxy
```

```{r Ssumsresults}
cbind(Sxx,Syy,Sxy)
```




##Ajuste do modelo de regressão linear simples e gráfico  da reta ajustada 

Note que na aula $3$ temos feito passo a passo do ajuste do modelos mediante o método de minimos quadrados (ajustar um modelo significa mesmo estimar seus parâmetros). Nosso modelo liear simples é da forma:
$$Y=\beta_0+\beta_1X+\xi$$ onde aplicando a técnica de mínimos quadrados teremos estimadores para nossos parâmetros dados pelas seguintes expressões:
$\widehat{\beta_0}=\overline{Y}-\widehat{\beta_1}\overline{X}\\\widehat{\beta_1}=\dfrac{Sxy}{Sxx}$. Portanto,

```{r betasest}
beta1est=(Sxy)/(Sxx)
beta0est=ybarra-(beta1est*xbarra)
cbind(beta0est,beta1est)
```


**Gráfico Reta Ajustada**
```{r grafajuste}
plot(x1,y , ylim = c(750,1150), xlim = c(9,65),
     main = expression(paste("Reta ajustada com ", 
                             hat(beta)[0],"=821,7546", 
                             " e ", hat(beta)[1],"=3,174")),
     xlab = "Precip", ylab = "Mortalidade")
curve(beta0est + beta1est*x, add = T, col = 'red')
```

Consequentemente, a reta ajustada é
$$\widehat{Y}_i=821.7546+3.174002*X_i$$

***Estimando $\sigma^2$***

O estimador de $\sigma^2$ não viesado eh obtido pelo quadrado médio do resíduo (QMres) apresentado passo a passo na aula $5$. Para termos QMreg precisamos do SQres.

**SQreg**
```{r sqreg}
SQreg <- beta1est*Sxy
SQreg
```

**SQtotal**
```{r sqtotal}
SQtotal <- sum((y-mean(y))^2)
SQtotal
```

**SQRes = SQtotal - SQreg**
```{r sqres}
SQres <- SQtotal - SQreg
SQres
```

**MQres**
```{r mqres}
#estimador nao viesado de sigma^2
QMres <- SQres/(n-2)
SigmaQuadradoEst<-QMres
SigmaQuadradoEst
```


```{r estimativ}
#Estimativas para Beta0, Beta1 e Sigma^2
cbind(beta0est, beta1est, SigmaQuadradoEst)

```



## Resíduos 

O valor dos $\widehat{Y}$'s e o valor dos resíduos para o seu modelo, faça um resumo e Histograma dos resíduos e faça análise da distribuição destes. 

Para sabermos os resíduos do nosso modelo vamos calcular o valor predito primeiro.

```{r valpredito}
# valor predito
y_pred <- beta0est + beta1est*x1
```

```{r ypredi}
# Ou ainda 
y_pred <- mean(y) + beta1est*(x1 - mean(x1))
```

***Resíduos***
```{r residuos}
res <- y - y_pred
res
summary(res)
```
***Histograma dos Resíduos***
```{r historesiduos}
hist(res, main = "Histograma dos Resíduos", col = "green",
     xlim = c(-151, 130), ylim = c(0, 30), 
     ylab = "Frequencia", xlab = "Resíduos")
```  
```{r qqplotresidu}
qqnorm(res)
qqline(res, col = "blue")
```


## Teste de Hipótese 

Obteremos os teste de hipóteses para $\beta_0$ e $\beta_1$ com a decisão de rejeitar ou não $H_0$.

Sera que $\beta_0 = 0$ estatísticamente? E sera que $\beta_1=0$ estatísticamente?. Para isso precisamos calcular o estimador de $\sigma^2$ (Utilizando $\alpha=5\%$).

***Teste de Hipótese para $\beta_1$***

Testando se $\beta_1 = 0$, Lembrando que $\beta_1$ estimado tem distribuição Normal com media $\beta_1$ e variância$=(\sigma^2/Sxx)$.

Como nâo temos o valor de $\sigma^2$ temos que estima-lo. 

$H_0: \beta_1 = 0$  vs $H_1: \beta_1$ não eh zero $(\beta_1\neq 0)$.

```{r estimabetas}
dp_b1 <- (sqrt(QMres/Sxx))
t0_b1 <- beta1est/dp_b1
```


Rejeitamos $H_0$ se t0_b1 $< t_1$ ou t0_b1 $> t_2$, em que $t_1$ eh o quantil $\alpha/2$ da Distribuição $t$ com $n-2$ G.L. e $t_2$ eh o quantil $1-\alpha/2$ da Distribuição $t$ com $n-2$ G.L. útilizando $\alpha = 5\%$.

```{r quantilst}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)
```

*Regra de Decisão*
```{r decisao}
if(t0_b1 < t1 || t0_b1>t2){
  cat("Rejeita-se H0")
}
```


Como podemos ver pelo teste, rejeitamos $H_0$. Ou seja, rejeitamos a hípotese que o valor do coeficiente $\beta_1 = 0$. 

***Teste de Hipótese para $\beta_0$***

Testando se $\beta_0 = 0$. Lembrando que $\beta_0$ estimado tem Distribuição Normal com média $\beta_0$ e variância$=(\sigma^2*((1/n)+ \overline{X}/Sxx))$ como não temos o valor de $\sigma^2$ temos que estima-lo. 

$H_0: \beta_0 = 0$  vs $H_1: \beta_0$ não eh zero $(\beta_0\neq 0)$
```{r nvotest}
dp_b0 <- (sqrt( QMres *( (1/n) + (mean(x1))^2/Sxx )))

t0_b0 <- beta0est/dp_b0
```

Rejeitamos $H_0$ se t0_b0 $< t_1$ ou t0_b0 $>t_2$, em que 
$t_1$ eh o quantil $\alpha/2$ da Distribuição $t$ com $(n-2)$ G.L.
$t_2$ eh o quantil $1-\alpha/2$ da Distribuicao $t$ com $(n-2)$ G.L.
útilizando $\alpha = 5\%$

```{r quantts}
alpha <- 0.05
t1 <- qt(alpha/2,n-2)
t2 <- qt(1-alpha/2,n-2)
```

*Regra de Decisão*
```{r desnov}
if(t0_b0 < t1 || t0_b0>t2){
  cat("Rejeita-se H0")
}
```


Como podemos ver pelo teste, rejeitamos $H_0$. 
Ou seja, rejeitamos a hípotese que o valor do 
intercepto $\beta_0 = 0$.



## ***Intervalos de Confiança*** 

Intervalos de Confiança para $(\beta_0,\beta_1,\sigma^2)$ e $E(Y)$.

***Calculando intervalo de Confiança para $\beta_1$***
```{r icbeta1}
b1_min <- beta1est-t2*dp_b1
b1_max <- beta1est-t1*dp_b1
IC_b1_est <- cbind(b1_min, b1_max)
IC_b1_est
```

**Interpretação:** Para cada Precip aumenta $3,17$ mortes com 
uma margem de erro de $1,4$ mortes para mais ou para menos. 

***Calculando intervalo de Confiança para $\beta_0$***
```{r icbeta0}
b0_min <- beta0est-t2*dp_b0
b0_max <- beta0est-t1*dp_b0
IC_b0_est <- cbind(b0_min, b0_max)
IC_b0_est
```

***Calculando intervalo de confiança para $\sigma^2$***

Lembrado que $SQres/\sigma^2$ tem Distribuição
qui-quadrado com $(n-2)$ G.L.
```{r icsigmaone}
t1_sig <- qchisq(alpha/2, n-2)
t2_sig <- qchisq(1-alpha/2,n-2)
```


```{r icsigmatwo}
sig_min <- SQres/t2_sig
sig_max <- SQres/t1_sig
```


```{r icsigmathree}
IC_sig_est <- cbind(sig_min, sig_max)
IC_sig_est
```

**Calculando intervalo de confiança para a esperança de y**

(valor medio da variavel resposta para um valor 
particular da cov., MIy|X0).

**Lembrando:**

1. O valor médio da variavél resposta é dado um $X_0$. 
2. $\overline{Y}$ tem Distribuição Normal. 
com média $\beta_0+\beta_1*\overline{X}$ e variância $\sigma^2/n$.
3. $\beta_1$ tem Distribuição Normal com média $\beta_1$ e variância
$\sigma^2/Sxx$. 
4. A Esperança de $Y|X_0$ é Normal.
5. a Variância de $MIy|X_0$ é $\sigma^2*(1/n + ((X_0-\overline{X}^2)/Sxx)$,
 $t_1 =$ quantil da dist. $t(\alpha/2,n-2)$,
 $t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$,
 $\alpha = 0,05$.

**Exemplo:**
Nesse exemplo usaremos $X_0$ como sendo o proprio $\overline{X}$.
```{r x0exbarra}
X0 <- mean(x1) # poderia ser outro valor

v_medio <- (mean(y)+beta1est* (X0-mean(x1)) )

auxiliar <- sqrt(QMres*(1/n + (X0 - mean(x1)) /Sxx ))
```

**Intervalo De Confiança**
```{r icmedio}
v_medio_min <- v_medio - t2*auxiliar
v_medio_max <- v_medio - t1*auxiliar

IC_v_medio <- cbind(v_medio_min, v_medio_max)
IC_v_medio
```

E se quisessemos predizer a mortalidade baseado em um novo valor
da variavel explicativa utilizada. Qual seria o intervalo 
que em $95\%$ das vezes iria conter o verdadeiro valor predito
considerando a nova informação de $x_1$ ?
(Ou seja, qual seria o Intervalo de Confiança para o valor 
predito de $Y$ baseado no novo valor da variavèl $x_1$ com $95\%$ 
de confiança).

## ***Intervalo de predição*** 

O intervalo de predição para até $5$ valores diferentes de $X_0$.

***Intervalos de predição***

*Lembrando:*

$Y_0$_est $= \beta_0$_est $+ \beta_1$_est$\ *\ x_1$_novo.

$Y_0$ e $Y_0$_est são independentes.

$t_1 =$ quantil da dist. $t(\alpha/2,n-2)$.

$t_2 =$ quantil da dist. $t(1-\alpha/2,n-2)$.

$\alpha = 0,05$.

***Exemplo***
```{r exem1}
x1_novo <- 12  
#x1_novo <- c(12,20,48,51,57,62)
Y0_est <- beta0est + beta1est*x1_novo
auxiliar_y0 <- sqrt(QMres*(1+ 1/n + (x1_novo - mean(x1)) /Sxx ))
```

```{r exey}
Y0_est_min <- Y0_est - t2*auxiliar_y0
Y0_est_max <- Y0_est - t1*auxiliar_y0
```

```{r ixexem}
IC_Y0_est <- cbind(Y0_est_min, Y0_est_max)
IC_Y0_est
```


## ***Análise de Variâcia*** 

A Análise de Variâcia com todos os valores (Graus de Liberdade, SQTotal, SQRes, SQReg, QMRes, QMReg e F).

***ANOVA***

 Teria outra forma de testarmos a significancia da regressão ?
 Sim! Outra forma seria pela Análise de Variância (ANOVA), nesse 
 caso testariamos se $\beta_1 = 0$.

**Soma do quadrado da Regressão**
```{r saqreganova}
SQreg <- beta1est*Sxy
SQreg
```

**Soma do quadrado total**
```{r asqtotalanova}
SQtotal <- sum((y-mean(y))^2)
SQtotal
```

**Soma do quadrado do resíduo**
```{r asqresanova}
SQres <- sum((y-mean(y))^2) - beta1est*Sxy
SQres
```

```{r sqresanova}
QMreg <- SQreg
QMreg
```

**Lembre-se que QMres eh o estimador de sigma^2 e QMres=SQres/(n-2)**
```{r faanova}
F_0 <- QMreg/QMres 
F_0
```

**Quantil da Distribuição F-Snedecor**
```{r f1aanova}
f1 <- pf(F_0, df1 = 1, df2 = n-2, lower.tail = F)
f1
```

```{r descisaaoanova}
if(F_0 > f1){
  cat("Rejeita-se H0")
}
```

**ou poderiamos ter calculado**
```{r alternaanova}
f1.2 <- pf(t0_b1^2, df1 = 1, df2 = n-2, lower.tail = F)
```

```{r desalteraanova}
if(t0_b1^2 > f1.2){
  cat("Rejeita-se H0")
}
```

***Anova usando funções do R***
```{r funanovar}
Anovamodel <- aov(MORT ~ PRECIP, data = data)
Anovamodel
```

```{r resumofunanovar}
summary(Anovamodel)
```

***Normalidade dos resíduos***
```{r normalidadtestresd}
shapiro.test(resid(Anovamodel))
```

A hipótese nula do Teste de Shapiro-Wilk é de que não há diferença entre a nossa distribuição dos dados e a distribuição normal. O valor-p maior do que 0.05 nos dá uma confiança estatística para afirmar que as distribuição dos nossos resíduos não difere da distribuição normal.

Dessa forma nossos dados satisfazem todas as premissas da ANOVA e portanto, o resultado da nossa ANOVA são válidos.




